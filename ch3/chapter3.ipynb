{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Linear Methods for Regression\n",
    "\n",
    "We have an input vector $X^T = (X_1, X_2, ..., X_p)$ and want to predict a real-valued ouput $Y$.  The linear regression model has the form\n",
    "\n",
    "$$ f(X) = \\beta_0 + \\sum_{j=1}^p \\, X_j \\, \\beta_j         \n",
    "\\tag{3.1}$$\n",
    "\n",
    "where the $\\beta_j$ are unknown parameters.  Note that if we add an element $X_0=1$ to $X^T = (1, X_1, X_2, ..., X_p)$ and absorb the *intercept* parameter $\\beta_0$ into the summation, we can write the regression model as a simple inner product\n",
    "\n",
    "$$ f(X) = \\sum_{j=0}^p \\, X_j \\, \\beta_j    \n",
    "\\tag{3.1a} $$\n",
    "\n",
    "Typically we have a set of training data $(x_1, y_1) ... (x_N, y_N)$ from which to estimate these parameters.  Each $x_i = (1, x_{i1}, x_{i2}, ...., x_{ip})^T$ is a vector of feature measurements for the $i$th case.  The most popular estimation method is *least squares*, in which we pick parameters $\\beta = (\\beta_0, \\beta_1, ..., \\beta_p)^T$ to minimize the residual sum of squares\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "{\\rm RSS}(\\beta) &= \\sum_{i=1}^{N} \\left[y_i - f(x_i)\\right]^2 \\\\\n",
    "&= \\sum_{i=1}^{N} \\left[ y_i - \\sum_{j=0}^p \\, x_{ij} \\, \\beta_j \\right]^2\n",
    "\\end{aligned}\n",
    "\\tag{3.2}\n",
    "$$\n",
    "\n",
    "If we construct an $N \\times (p+1)$ matrix from the vectors $x_i$ (sometimes called the design matrix) we can express $RSS(\\beta)$ using only matrix operations\n",
    "\n",
    "$$\n",
    "{\\bf X} = \n",
    "\\begin{bmatrix}\n",
    "    1       & x_{11} & x_{12} & \\dots & x_{1p} \\\\\n",
    "    1       & x_{21} & x_{22} & \\dots & x_{2p} \\\\\n",
    "    \\vdots  & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    1       & x_{N1} & x_{N2} & \\dots & x_{Np}\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "{\\bf y} = \n",
    "\\begin{bmatrix}\n",
    "    y_{1} \\\\\n",
    "    y_{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    y_{N}\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\beta = \n",
    "\\begin{bmatrix}\n",
    "    \\beta_{0} \\\\\n",
    "    \\beta_{1} \\\\\n",
    "    \\beta_{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\beta_{p}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$ {\\rm RSS}(\\beta) = ({\\bf y} - {\\bf X} \\beta)^T ({\\bf y} - {\\bf X} \\beta) \n",
    "\\tag{3.3}$$\n",
    "\n",
    "This is a quadratic function in the $p+1$ parameters $\\beta$. Differentiating with respect to $\\beta$ we obtain\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial {\\rm RSS}}{\\partial \\beta} &= -2 {\\bf X}^T ({\\bf y} - {\\bf X} \\beta) \\\\\n",
    "\\frac{\\partial^2 {\\rm RSS}}{\\partial \\beta \\, \\partial \\beta^T} &= 2 {\\bf X}^T {\\bf X}\n",
    "\\end{aligned}\n",
    "\\tag{3.4}\n",
    "$$\n",
    "\n",
    "Assuming (for the moment) that ${\\bf X}$ has full column rank (i.e. the columns=features are linearly independent), and hence ${\\bf X}^T {\\bf X}$ is positive definite, we set the first derivative to zero\n",
    "\n",
    "$$ {\\bf X}^T ({\\bf y} - {\\bf X} \\beta) = 0 \n",
    "\\tag{3.5}$$\n",
    "\n",
    "to obtain the unique solution\n",
    "\n",
    "$$ \n",
    "\\hat{\\beta} = ({\\bf X}^T {\\bf X})^{-1} {\\bf X}^T {\\bf y} \n",
    "\\tag{3.6}$$\n",
    "\n",
    "The fitted values at the training inputs are \n",
    "$$\\hat{\\bf y} = {\\bf X} \\hat{\\beta} = {\\bf X}({\\bf X}^T {\\bf X})^{-1} {\\bf X}^T {\\bf y} \n",
    "\\tag{3.7}\n",
    "$$\n",
    "\n",
    "Up to now we have made minimal assumptions about the true distribution of the data.  In order to pin down the sampling properties of $\\hat{\\beta}$, we now assume that the observations $y_i$ are uncorrelated and have constant variance $\\sigma^2$, and that the $x_i$ are fixed (non random).  The covariance matrix of the least squares parameter estimates is easily derived from (3.6) and is given by\n",
    "\n",
    "$$ {\\rm Var}(\\hat{\\beta}) = ({\\bf X}^T {\\bf X})^{-1} \\sigma^2 \n",
    "\\tag{3.8}$$\n",
    "\n",
    "Typically one estimates the variance $\\sigma^2$ by \n",
    "\n",
    "$$ \\hat{\\sigma}^2 = \n",
    "\\frac{\\sum_{i=1}^{N}\\left( y_i - \\hat{y}_i \\right)^2} {N - p - 1} = \n",
    "\\frac{({\\bf y} - {\\bf \\hat{y}})^T ({\\bf y} - {\\bf \\hat{y}})} {N - p - 1}\n",
    "$$\n",
    "\n",
    "The $N - p - 1$ rather than $N$ in the denominator makes $\\hat{\\sigma}^2$ an unbiased estimate of $\\sigma^2: {\\rm E}(\\hat{\\sigma}^2) = \\sigma^2$.  \n",
    "\n",
    "To test the hypothesis that a particular parameter $\\beta_j=0$, we form the standardized parameter or *Z-score*\n",
    "\n",
    "$$\n",
    "z_j = \\frac{\\hat{\\beta}_j}{\\hat{\\sigma} \\sqrt{v_j}} = \n",
    "\\frac{\\hat{\\beta}_j}{\\sqrt{diag \\left( {\\rm Var}(\\hat{\\beta}) \\right)_j}} \n",
    "\\tag{3.12}\n",
    "$$\n",
    "\n",
    "where $v_j$ is the $j$th diagonal element of $({\\bf X}^T {\\bf X})^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prostate Data Example\n",
    "\n",
    "Lets explore the prostate data set provided at the book website https://statweb.stanford.edu/~tibs/ElemStatLearn/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pandas.read_csv('../data/prostate.data', delimiter='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.579818</td>\n",
       "      <td>2.769459</td>\n",
       "      <td>50</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430783</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.994252</td>\n",
       "      <td>3.319626</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.510826</td>\n",
       "      <td>2.691243</td>\n",
       "      <td>74</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.203973</td>\n",
       "      <td>3.282789</td>\n",
       "      <td>58</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.162519</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>3.432373</td>\n",
       "      <td>62</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lcavol   lweight  age      lbph  svi       lcp  gleason  pgg45      lpsa  \\\n",
       "1 -0.579818  2.769459   50 -1.386294    0 -1.386294        6      0 -0.430783   \n",
       "2 -0.994252  3.319626   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "3 -0.510826  2.691243   74 -1.386294    0 -1.386294        7     20 -0.162519   \n",
       "4 -1.203973  3.282789   58 -1.386294    0 -1.386294        6      0 -0.162519   \n",
       "5  0.751416  3.432373   62 -1.386294    0 -1.386294        6      0  0.371564   \n",
       "\n",
       "  train  \n",
       "1     T  \n",
       "2     T  \n",
       "3     T  \n",
       "4     T  \n",
       "5     T  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a target variable (`lpsa`), a boolean column splitting the data into train and test sets (`train`), and 8 predictor variables (all the rest).  Lets look at the training data and calculate some of its properties.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N(number of training samples)=67, p(number of features)=8\n"
     ]
    }
   ],
   "source": [
    "# pull out training set and split into predictor variables and the target variable\n",
    "predictors = ['lcavol', 'lweight', 'age', 'lbph', 'svi', 'lcp', 'gleason', 'pgg45']\n",
    "df_X = df.loc[df['train']=='T', predictors]\n",
    "# center on the means and scale to have unit standard deviation\n",
    "df_X = (df_X - df_X.mean()) / df_X.std()\n",
    "\n",
    "\n",
    "target = ['lpsa']\n",
    "df_y = df.loc[df['train']=='T', target]\n",
    "\n",
    "\n",
    "N, p = df_X.shape\n",
    "print('N(number of training samples)={}, p(number of features)={}'.format(N,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300232</td>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.483161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.300232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.074166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.286324</td>\n",
       "      <td>0.316723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.275806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.437042</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>-0.030404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.128902</td>\n",
       "      <td>-0.139147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.481358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>0.692043</td>\n",
       "      <td>0.156829</td>\n",
       "      <td>0.172951</td>\n",
       "      <td>-0.088535</td>\n",
       "      <td>0.671240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>0.662533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>0.426414</td>\n",
       "      <td>0.023558</td>\n",
       "      <td>0.365915</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.306875</td>\n",
       "      <td>0.476437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.483161</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>0.275806</td>\n",
       "      <td>-0.030404</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.662533</td>\n",
       "      <td>0.757056</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lcavol   lweight       age      lbph       svi       lcp   gleason  \\\n",
       "lcavol   1.000000  0.300232  0.286324  0.063168  0.592949  0.692043  0.426414   \n",
       "lweight  0.300232  1.000000  0.316723  0.437042  0.181054  0.156829  0.023558   \n",
       "age      0.286324  0.316723  1.000000  0.287346  0.128902  0.172951  0.365915   \n",
       "lbph     0.063168  0.437042  0.287346  1.000000 -0.139147 -0.088535  0.032992   \n",
       "svi      0.592949  0.181054  0.128902 -0.139147  1.000000  0.671240  0.306875   \n",
       "lcp      0.692043  0.156829  0.172951 -0.088535  0.671240  1.000000  0.476437   \n",
       "gleason  0.426414  0.023558  0.365915  0.032992  0.306875  0.476437  1.000000   \n",
       "pgg45    0.483161  0.074166  0.275806 -0.030404  0.481358  0.662533  0.757056   \n",
       "\n",
       "            pgg45  \n",
       "lcavol   0.483161  \n",
       "lweight  0.074166  \n",
       "age      0.275806  \n",
       "lbph    -0.030404  \n",
       "svi      0.481358  \n",
       "lcp      0.662533  \n",
       "gleason  0.757056  \n",
       "pgg45    1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check out the correlations (figure 3.1)\n",
    "corrmat = df_X.corr()\n",
    "corrmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fee5a5b0550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5UAAAO2CAYAAAB4kLNLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiSpmkGlJEmSJKna/wA8vAa0FG+lcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee5aa47be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "sns.heatmap(corrmat, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sig2_hat= 0.5073514562053173\n",
      "shape(cvmat_beta_hat)= (9, 9)\n",
      "\n",
      "           coefficient   std_err      z_hat\n",
      "intercept     2.452345  0.087020  28.181527\n",
      "lcavol        0.716407  0.133501   5.366290\n",
      "lweight       0.292642  0.106385   2.750789\n",
      "age          -0.142550  0.102120  -1.395909\n",
      "lbph          0.212008  0.103124   2.055846\n",
      "svi           0.309620  0.125390   2.469255\n",
      "lcp          -0.289006  0.154804  -1.866913\n",
      "gleason      -0.020914  0.142578  -0.146681\n",
      "pgg45         0.277346  0.159592   1.737840\n"
     ]
    }
   ],
   "source": [
    "# casting these to matrices allows us to use \"*\" as matrix multiplication \n",
    "# as opposed to point-wise multiplication for numpy arrays. \n",
    "X = np.matrix(df_X.values)\n",
    "y = np.matrix(df_y.values)\n",
    "\n",
    "# add a column of ones so we don't have to treat the intercept differently\n",
    "X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "# use the normal equation (Eq. 3.6) to calculate the coefficients and predictions\n",
    "beta_hat = np.linalg.pinv(X.T * X) * X.T * y\n",
    "y_hat = X * beta_hat\n",
    "\n",
    "# estimate the variance of y\n",
    "sig2_hat = float((y-y_hat).T*(y-y_hat)/(N-p-1))\n",
    "sig_hat = np.sqrt(sig2_hat)\n",
    "\n",
    "# calculate the covariance matrix of beta\n",
    "cvmat_beta_hat = np.linalg.inv(X.T * X) * sig2_hat\n",
    "\n",
    "# note <matrix>.A returns a numpy array of self\n",
    "#      <matrix>.A1 returns a flattened numpy array of self\n",
    "std_err = np.sqrt(cvmat_beta_hat.diagonal().A1)\n",
    "z_hat = beta_hat.A1 / std_err\n",
    "\n",
    "print('sig2_hat=',sig2_hat)\n",
    "print('shape(cvmat_beta_hat)=', cvmat_beta_hat.shape)\n",
    "\n",
    "df_coefs = pandas.DataFrame({\n",
    "        'coefficient': beta_hat.A1, \n",
    "        'std_err': std_err, \n",
    "        'z_hat': z_hat}, \n",
    "        index=['intercept']+predictors)\n",
    "print()\n",
    "print(df_coefs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.45234508507 2.45234508507 -1.7763568394e-15\n",
      "1 0.71640701248 0.71640701248 8.881784197e-16\n",
      "2 0.29264240076 0.29264240076 5.55111512313e-16\n",
      "3 -0.142549625985 -0.142549625985 -1.38777878078e-16\n",
      "4 0.212007604489 0.212007604489 4.71844785466e-16\n",
      "5 0.309619533067 0.309619533067 0.0\n",
      "6 -0.289005615691 -0.289005615691 -4.99600361081e-16\n",
      "7 -0.0209135198219 -0.0209135198219 5.6898930012e-16\n",
      "8 0.277345952502 0.277345952502 -1.66533453694e-16\n"
     ]
    }
   ],
   "source": [
    "# compare the parameters to those calculated from scikit-learn\n",
    "# note \"fit_intercept=False\" means we dont need the value that \n",
    "# would usually be in mdl.intercept_ b/c we will have it as the \n",
    "# first element of mdl.coef_\n",
    "mdl = linear_model.LinearRegression(fit_intercept=False)\n",
    "mdl.fit(X, y)\n",
    "\n",
    "for i in range(mdl.coef_.shape[1]):\n",
    "    beta_hat_i = beta_hat[i,0] # (p+1 X 1) matrix\n",
    "    skt_i = mdl.coef_[0,i] # (1 X p+1) matrix\n",
    "    print(i, beta_hat_i, skt_i, beta_hat_i - skt_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statsmodels Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   lpsa   R-squared:                       0.694\n",
      "Model:                            OLS   Adj. R-squared:                  0.652\n",
      "Method:                 Least Squares   F-statistic:                     16.47\n",
      "Date:                Sat, 27 May 2017   Prob (F-statistic):           2.04e-12\n",
      "Time:                        17:49:22   Log-Likelihood:                -67.505\n",
      "No. Observations:                  67   AIC:                             153.0\n",
      "Df Residuals:                      58   BIC:                             172.9\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "intercept      2.4523      0.087     28.182      0.000         2.278     2.627\n",
      "lcavol         0.7164      0.134      5.366      0.000         0.449     0.984\n",
      "lweight        0.2926      0.106      2.751      0.008         0.080     0.506\n",
      "age           -0.1425      0.102     -1.396      0.168        -0.347     0.062\n",
      "lbph           0.2120      0.103      2.056      0.044         0.006     0.418\n",
      "svi            0.3096      0.125      2.469      0.017         0.059     0.561\n",
      "lcp           -0.2890      0.155     -1.867      0.067        -0.599     0.021\n",
      "gleason       -0.0209      0.143     -0.147      0.884        -0.306     0.264\n",
      "pgg45          0.2773      0.160      1.738      0.088        -0.042     0.597\n",
      "==============================================================================\n",
      "Omnibus:                        0.825   Durbin-Watson:                   1.690\n",
      "Prob(Omnibus):                  0.662   Jarque-Bera (JB):                0.389\n",
      "Skew:                          -0.164   Prob(JB):                        0.823\n",
      "Kurtosis:                       3.178   Cond. No.                         4.44\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "df_Xsm = df_X.copy()\n",
    "df_Xsm.insert(0, 'intercept', 1)\n",
    "results=sm.OLS(df_y, df_Xsm).fit()\n",
    "print(results.summary())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
